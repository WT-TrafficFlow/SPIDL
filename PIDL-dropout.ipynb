{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6f051-c7e1-4fad-98ef-92e460187cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from pyDOE import lhs\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" \n",
    "np.random.seed(0)\n",
    "tf.random.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd791f8-b4b6-4a3f-abf3-87425ff12896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PhysicsInformedNN:\n",
    "    it = 0\n",
    "    \n",
    "    def __init__(self, X_u, u, X_f, layers,lb, ub,vf,rho_j,dropout_rate=0.05):\n",
    "        self.vf = vf\n",
    "        self.rho_j = rho_j\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "    \n",
    "        self.x_u = X_u[:,0:1]\n",
    "        self.t_u = X_u[:,1:2]\n",
    "        \n",
    "        self.x_f = X_f[:,0:1]\n",
    "        self.t_f = X_f[:,1:2]\n",
    "        \n",
    "        self.v = u[:,0:1]\n",
    "        self.rho = u[:,1:2]\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        \n",
    "        self.x_u_tf = tf.placeholder(tf.float32, shape=[None, self.x_u.shape[1]])\n",
    "        self.t_u_tf = tf.placeholder(tf.float32, shape=[None, self.t_u.shape[1]])        \n",
    "        self.v_tf = tf.placeholder(tf.float32, shape=[None, self.v.shape[1]])\n",
    "        self.rho_tf = tf.placeholder(tf.float32, shape=[None, self.rho.shape[1]])\n",
    "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
    "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, self.t_f.shape[1]])   \n",
    "        \n",
    "        self.keep_prob = tf.placeholder_with_default(0.95, shape=())\n",
    "                \n",
    "        self.v_pred, self.rho_pred = self.net_u(self.x_u_tf, self.t_u_tf) \n",
    "        self.f_pde, self.f_fd, self.f_loss = self.net_f(self.x_f_tf, self.t_f_tf) \n",
    "        \n",
    "        self.loss = 0.4 * tf.reduce_mean(tf.square(self.v_tf - self.v_pred)) + 0.6 * tf.reduce_mean(tf.square(self.rho_tf - self.rho_pred)) +\\\n",
    "                         0.5* tf.reduce_mean(tf.square(self.f_pde)) + 0.5 *  tf.reduce_mean(tf.square(self.f_fd)) \n",
    "                         \n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 50000,\n",
    "                                                                           'maxfun': 50000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer(0.001)\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_NN(self, layers):  \n",
    "        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0, num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "    \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0         # scaling\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "            H = tf.nn.dropout(H, keep_prob=self.keep_prob)  #  dropout\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "            \n",
    "    def net_u(self, x, t):\n",
    "        u = self.neural_net(tf.concat([x,t],1), self.weights, self.biases)\n",
    "        v = u[:,0:1]\n",
    "        rho = u[:,1:2]\n",
    "        return v,rho\n",
    "    \n",
    "    def net_f(self, x,t):\n",
    "        v,rho = self.net_u(x,t)\n",
    "        rho_t = tf.gradients(rho, t)[0] \n",
    "        rho_x = tf.gradients(rho, x)[0]\n",
    "        v_x = tf.gradients(v, x)[0]\n",
    "        f_pde = rho_t + rho * v_x + v * rho_x       #LWR的loss\n",
    "        f_fd = self.vf * tf.exp(-rho/self.rho_j)-v  #基本图loss\n",
    "        fd = self.vf * tf.exp(-rho/self.rho_j)     \n",
    "        f_pde_2 = v + vf- fd     \n",
    "        f_pde_3 = fd - v\n",
    "        f_pde_2_t = tf.gradients(f_pde_2, t)[0]    \n",
    "        f_pde_2_x = tf.gradients(f_pde_2, x)[0] \n",
    "        f_loss = f_pde_2_t + v * f_pde_2_x - (f_pde_3)/30   #二阶ARZ\n",
    "        return f_pde, f_fd, f_loss\n",
    "\n",
    "    def callback(self, loss):\n",
    "        print('Loss:', loss)\n",
    "        \n",
    "    def train(self,nIter):     \n",
    "        \n",
    "        tf_dict = {self.x_u_tf: self.x_u, self.t_u_tf: self.t_u, self.v_tf: self.v,self.rho_tf: self.rho,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f, self.keep_prob: 1 - self.dropout_rate}   \n",
    "        \n",
    "        start_time = time.time()\n",
    "        MSE_history=[]\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            if it %100 == 0:\n",
    "                loss_value = self.sess.run(self.loss, tf_dict)\n",
    "                print('It: %d, Loss: %.3e' % \n",
    "                      (it, loss_value))\n",
    "                MSE_history.append(loss_value)\n",
    "        self.optimizer.minimize(self.sess, \n",
    "                                feed_dict = tf_dict,         \n",
    "                                fetches = [self.loss], \n",
    "                                loss_callback = self.callback)        \n",
    "        return MSE_history\n",
    "    \n",
    "    def predict(self, X_star):      \n",
    "            \n",
    "        v_star = self.sess.run(self.v_pred, {self.x_u_tf: X_star[:,0:1], self.t_u_tf: X_star[:,1:2],self.keep_prob: 1 - self.dropout_rate})  \n",
    "        rho_star = self.sess.run(self.rho_pred, {self.x_u_tf: X_star[:,0:1], self.t_u_tf: X_star[:,1:2],self.keep_prob: 1 - self.dropout_rate})  \n",
    "                \n",
    "        f_v_star = self.sess.run(self.f_pde, {self.x_f_tf: X_star[:,0:1], self.t_f_tf: X_star[:,1:2]})\n",
    "        f_rho_star = self.sess.run(self.f_fd, {self.x_f_tf: X_star[:,0:1], self.t_f_tf: X_star[:,1:2]})\n",
    "        \n",
    "        return v_star, rho_star\n",
    "    \n",
    "    \n",
    "    def predict_mc(self, X_star, n_samples=50):\n",
    "       \n",
    "        v_samples = []\n",
    "        rho_samples = []\n",
    "        \n",
    "        print('n_samples',n_samples)\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            tf_dict = {\n",
    "                self.x_u_tf: X_star[:, 0:1],\n",
    "                self.t_u_tf: X_star[:, 1:2],\n",
    "                self.keep_prob: 1 - self.dropout_rate  \n",
    "            }\n",
    "            v_pred = self.sess.run(self.v_pred, tf_dict)\n",
    "            print('---------------------------',v_pred)\n",
    "            rho_pred = self.sess.run(self.rho_pred, tf_dict)\n",
    "            v_samples.append(v_pred)\n",
    "            rho_samples.append(rho_pred)\n",
    "\n",
    "        v_samples = np.stack(v_samples, axis=0)\n",
    "        rho_samples = np.stack(rho_samples, axis=0)\n",
    "        \n",
    "\n",
    "        v_mean = np.mean(v_samples, axis=0)\n",
    "        rho_mean = np.mean(rho_samples, axis=0)\n",
    "        v_std = np.std(v_samples, axis=0)\n",
    "        rho_std = np.std(rho_samples, axis=0)\n",
    "\n",
    "        return v_mean, rho_mean, v_std, rho_std,v_samples,rho_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c815b-ca63-4c57-bab3-410ca8f3f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    layers = [2, 64, 64, 64, 64, 64, 64, 64, 64, 64, 2] #######\n",
    "    \n",
    "    import pickle\n",
    "    file = open('US101_Lane1to5_t1.5s30.pickle', 'rb')\n",
    "    info = pickle.load(file)\n",
    "    speed=info['vMat'].T\n",
    "    density = info['rhoMat'].T\n",
    "    flat_arrayv = speed.flatten()\n",
    "    flat_arrayrho = density.flatten()\n",
    "    \n",
    "    t=info['t']\n",
    "    x=info['s']\n",
    "    X, T = np.meshgrid(x,t)\n",
    "    df = pd.DataFrame({'speed': flat_arrayv, 'density': flat_arrayrho,'x':x * 1770})\n",
    "    # ------------- alpha = 0.01 --------------\n",
    "    # vf = 26.5932\n",
    "    # rho_j = 0.3008\n",
    "    # ---------------------------\n",
    "    # ------------- alpha = 0.08 --------------\n",
    "    # vf = 25.1762\n",
    "    # rho_j = 0.2663\n",
    "    # ---------------------------\n",
    "     # ------------- alpha = 0.15 --------------\n",
    "    # vf = 24.8948\n",
    "    # rho_j = 0.2491\n",
    "    # ---------------------------\n",
    "     # ------------- alpha = 0.22 --------------\n",
    "    # vf = 24.6698\n",
    "    # rho_j = 0.2386\n",
    "    # ---------------------------\n",
    "    # ------------- alpha = 0.29 --------------\n",
    "    # vf = 24.4427\n",
    "    # rho_j = 0.2314\n",
    "    # ---------------------------\n",
    "    # ------------- alpha = 0.36 --------------\n",
    "    # vf = 24.2222\n",
    "    # rho_j = 0.2256\n",
    "    # ---------------------------\n",
    "    # ------------- alpha = 0.43 --------------\n",
    "    # vf = 24.0017\n",
    "    # rho_j = 0.2207\n",
    "    # ---------------------------\n",
    "    # ------------- alpha = 0.50 --------------\n",
    "    vf = 23.7619\n",
    "    rho_j = 0.2164\n",
    "    # ---------------------------\n",
    "    # # ------------- alpha = 0.57 --------------\n",
    "    # vf = 23.4925\n",
    "    # rho_j = 0.2125\n",
    "    # # ---------------------------\n",
    "    # ------------- alpha = 0.64 --------------\n",
    "    # vf = 23.1839\n",
    "    # rho_j = 0.2089\n",
    "    # # ---------------------------\n",
    "    # ------------- alpha = 0.71 --------------\n",
    "    # vf = 22.8114\n",
    "    # rho_j = 0.2053\n",
    "    # # ---------------------------\n",
    "    # ------------- alpha = 0.78 --------------\n",
    "    # vf = 22.3361\n",
    "    # rho_j = 0.2018\n",
    "    # # ---------------------------\n",
    "    # ------------- alpha = 0.85 --------------\n",
    "    # vf = 21.7062\n",
    "    # rho_j = 0.1977\n",
    "    # # ---------------------------\n",
    "    # ------------- alpha = 0.92 --------------\n",
    "    # vf = 20.6696\n",
    "    # rho_j = 0.1926\n",
    "    # # ---------------------------\n",
    "    # ------------- alpha = 0.99 --------------\n",
    "    # vf = 15.7383\n",
    "    # rho_j = 0.1892\n",
    "    # # ---------------------------\n",
    "    \n",
    "    \n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    u_star = df.loc[:,['speed','density']]\n",
    "    \n",
    "    u_star = np.array(u_star.iloc[:,:])              \n",
    "    \n",
    "    \n",
    "    lb = X_star.min(0)\n",
    "    ub = X_star.max(0)  \n",
    "    \n",
    "\n",
    "    m = 12\n",
    "    if m == 12:\n",
    "        loopidx = [0,1,2,4,6,8,10,12,14,16,18,20]\n",
    "    else:\n",
    "        gap = int(len(x)/(m-1))\n",
    "        loopidx = [i*gap for i in range(m-1)]\n",
    "        loopidx.append(len(x)-1)\n",
    "    span = np.array(loopidx)\n",
    "    X_u_train = np.hstack([np.meshgrid(np.array(x)[span],t)[0].reshape(-1,1), np.meshgrid(np.array(x)[span],t)[1].reshape(-1,1) ])\n",
    "    u_train = df[df['x'].isin(df.loc[span,:]['x'])].loc[:,['speed','density']]\n",
    "    u_train = np.array(u_train.iloc[:,:])\n",
    "    idx2 = np.random.choice(X_star.shape[0], int(X_star.shape[0] * 0.6), replace=False)\n",
    "    X_f_train = X_star[idx2,:]\n",
    "    data_list = [[] for i in range(2)]\n",
    "    X_u_train = X_u_train[:, :]\n",
    "    u_train = u_train[:,:]\n",
    "\n",
    "    model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers,lb, ub,vf,rho_j,dropout_rate=0.05)\n",
    "    start_time = time.time()                \n",
    "    model.train(20000)\n",
    "    elapsed = time.time() - start_time                \n",
    "    print('Training time: %.4f' % (elapsed))\n",
    "\n",
    "    v_pred, rho_pred = model.predict(X_star)\n",
    "    print(v_pred)\n",
    "    print(flat_arrayv)\n",
    "\n",
    "\n",
    "    v_mean, rho_mean, v_std, rho_std,v_samples,rho_samples = model.predict_mc(X_star, n_samples=50)\n",
    "    print(\"速度预测均值:\", v_mean.flatten()[:5])\n",
    "    print(\"速度预测标准差:\", v_std.flatten()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae540197-49d7-4cc6-a9a7-2d2831abac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pred = griddata(X_star, v_pred.flatten(), (X, T), method='cubic')\n",
    "rho_pred = griddata(X_star, rho_pred.flatten(), (X, T), method='cubic')\n",
    "# path= r'/root/autodl-tmp/code_planA/PIDL_LWR_10loops'\n",
    "# import os\n",
    "# np.save(os.path.join(path,'dropout_'+str(0.05)+'v_alpha'+ str(0.50) + '_lwr_loop'+str(m) + '.npy'),arr=v_pred)#######\n",
    "# np.save(os.path.join(path,'dropout_'+str(0.05)+'rho_alpha'+ str(0.50) + '_lwr_loop'+str(m) + '.npy'),arr=rho_pred)#######\n",
    "# np.save(os.path.join(path,'dropout_'+str(0.05)+'meanv_alpha'+ str(0.50) + '_lwr_loop'+str(m) + '.npy'),arr=v_mean)#######\n",
    "# np.save(os.path.join(path,'dropout_'+str(0.05)+'meanrho_alpha'+ str(0.50) + '_lwr_loop'+str(m) + '.npy'),arr=rho_mean)#######\n",
    "# np.save(os.path.join(path,'dropout_'+str(0.05)+'stdv_alpha'+ str(0.50) + '_lwr_loop'+str(m) + '.npy'),arr=v_std)#######\n",
    "# np.save(os.path.join(path,'dropout_'+str(0.05)+'stdrho_alpha'+ str(0.50) + '_lwr_loop'+str(m) + '.npy'),arr=rho_std)#######\n",
    "# np.save(os.path.join(path,'sample50_dropout_'+str(0.05)+'v_alpha'+ str(0.50) + '_lwr_loop'+str(m) + '.npy'),arr=v_samples)#######\n",
    "# np.save(os.path.join(path,'sample50_dropout_'+str(0.05)+'rho_alpha'+ str(0.50) + '_lwr_loop'+str(m) + '.npy'),arr=rho_samples)#######"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
